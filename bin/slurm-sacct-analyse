#!/usr/bin/env ruby
#
# Copyright 2016 Victor Penso
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#

VERSION = 0.33

require 'ostruct'
require 'getoptlong' 
require 'logger'
require 'json'
require 'date'

exec_name = File.split(__FILE__)[-1]
HELP = <<EOF
Read accounting data from Slurm and accumulate statistics:

#{exec_name} [<options>] <start_time> [<end_time>]

  start_time                 Select accouting data after start time
                             Time format like `sacct`...
  end_time                   Select accounting data before end time
                             (default is now)

By default statistics are accumulated by account, select statistics
for partitions or users with following options:

  --partitions, -P           Show partition statistics.
  --users, -U                Show users statistics.

Limit the output to a given list of accounts, nodes,  partitions or users:

  --account, -a <acc,acc>    Limit the output to a given list of accounts
  --node-regex, -n <regex>   Regular expression to select a subset of nodes
  --partition, -p <par,par>  Limit the output ot a given list of partitions
  --user, -u <usr,usr>       Limit the output to a given list of users

Enable additional statistics for job exist states and job run-time with:

  --run-time, -R             Show accumulative statistics of job run-times. 
  --states, -S               Show job states.

Other options:

  --sort-by, -s r|p          Sort output by (r)untime, rel. (p)ercent
  --debug, -d                Show stacktraces in case of errors.
  --help, -H                 Show this help information.
  --no-header, -N            Disable header information in the output.
  --parsable, -X <delim>     Print output with given delimiter
  --version, -v              Print version number.

Columns in the output:

  ACCT                       Account name or number of accounts.
  USER                       User name or number of users.
  PART                       Partitions name or number of partitiosn.
  USE%                       Relative use of the cluster in percent from the 
                             selected data set.
  SHR%                       Normalized fair share in percent
  QWM                        Median time jobs waited in the queue, format [DD-]HH:MM
  RUNTIME                    Total run-time in seconds
  JOBS                       Total number of jobs
  CO                         Total number of completed jobs
  CA                         Total number of canceled jobs
  F                          Total number of failed jobs
  NF                         Total number of node failers
  TO                         Total number of jobs ended by time out
  <5m                        Number of jobs with a run-time sorter then 5 minutes
  <1h                        Number of jobs with a run-time sorter then 1 hour
  <4h                        Number of jobs with a run-time sorter then 4 hours
  <8h                        Number of jobs with a run-time sorter then 8 hours
  <12h                       Number of jobs with a run-time sorter then 12 hours
  <1d                        Number of jobs with a run-time sorter then 1 day
  <7d                        Number of jobs with a run-time sorter then 7 days
  >7d                        Number of jobs with a run-time longer then 7 days

Examples:

Show job staistics for a sub-set of nodes called "lxbk", sorted by
realtive use in percent:

  >>> sacct-analyse -s p -S -n lxbk 2016-04-01T00:00:00 2016-04-10T23:59:59

Limit the output to a given user:

  >>> sacct-analyse -u vpenso -U $(date +%Y-%m-%dT00:00:00) -d

List user of a given account by relative usage in a parsable format:

  >>> sacct-analyse -X "|" -a alice -U -s r 2016-05-20T12:00:00
EOF

#
# Interface to the command-line environment
#
module System

  module_function

  ##
  # Execute a command passed as parameter an return the output
  # on success. Otherwise the method returns Nil indicating
  # a problem on execution.
  def exec(command)
    command + ' 2>&1'
    $logger.debug "Exec [#{command}]"
    # Execute command as subprocess and return the exit code
    pipe = IO.popen(command)
    # Get the process ID from the child
    pid = pipe.pid
    # Read the output from the stream
    output = pipe.read
    # Wait for successful return and pass back the code to the caller
    Process.wait(pid)
    state=$?
    $logger.debug "Returned with #{state}"
    $logger.debug "No output received" if output.empty?
    if state == 0
      return output
    else
      $logger.warn "Failed to execute [#{command}]"
      return nil
    end
  end

  ##
  # Execute a command and transform the output line by line
  # into an array splitting each line using a delimiter into
  # a second level array.
  #
  def self.exec_split_lines(command, delimiter = ' ')
    r_val = Array.new
    # Remove line-feed and leading white-space
    #
    command = command.gsub(/^  */,'').gsub(/\n/,' ')
    # Execute the command and split the output by line
    #
    System::exec(command).split("\n").each do |line|
      # Use the defined delimiter to split the fields per line
      #
      r_val << line.split(delimiter).map! { |e| e.strip }
    end
    # Pass the output multi-dimensional array to the caller
    #
    r_val
  end


end

#
# Print an array as table with padded columns
#
class Table

  def initialize(output)
    @output = output
  end

  def self.print(table)
    Table.new(table).rows
  end

  def rows
    form = format()
    rows = String.new
    @output.each do |row|
      $logger.debug("#{row.inspect}")
      rows << sprintf("#{form}\n", *row)
    end
    return rows
  end

  def format
    format = Array.new
    columns = @output.first.length
    0.upto(columns-1) do |column|
      format << "%#{field_width(column)}s"
    end
    return format.join(' ')
  end

  def field_width(field = 0)
    max_width = 0
    @output.each do |row|
      elem = row[field].to_s
      next if elem.empty?
      width = elem.length
      max_width = width if width > max_width
    end
    return max_width
  end

end

module Slurm

  # List of fields queried during data export
  #
  SACCT_FIELDS = %w( 
    jobid
    cluster
    partition
    account
    group
    gid
    user
    uid
    submit
    priority
    eligible
    start
    end
    elapsed
    exitcode
    state
    nnodes
    ncpus
    ntasks
    reqcpus
    reqmem 
    timelimit
    cputime
    cputimeraw
    nodelist
    jobname
    alloccpus
  )

  SSHARE_FIELDS = %w(
    account
    user
    rawshares
    normshares
    rawusage
    normusage
    effectvusage
    fairshare
  )

  # List of job states queried during data export 
  #
  SACCT_STATES = %w(
    cancelled 
    completed 
    failed    
    node_fail 
    timeout  
  )

  module_function

  def sacct_fields ; SACCT_FIELDS.join(',') end
  def sshare_fields ; SSHARE_FIELDS.join(',') end
  def sacct_states ; SACCT_STATES.join(',') end

  ##
  # Returns th positional number of a specified field name
  #
  def sacct_findex(field) ; SACCT_FIELDS.index(field) end

  ##
  # Returns th positional number of a specified field name
  #
  def sshare_findex(field) ; SSHARE_FIELDS.index(field) end

  ##
  # Generate the command to export data from Slurm with sacct
  #
  def sacct(start_time,end_time,append = '')
    #
    # Note that option --allusers is required to make sure that unprivileged 
    # user will query data...
    #
    command = "sacct
                 --allusers
                 --noheader
                 --allocations
                 --parsable2
                 --format #{sacct_fields}
                 --state #{sacct_states}
                 --starttime #{start_time}
                 --endtime #{end_time}
              "
    command << " #{append}" unless append.empty?
    command.gsub!(/^  */,'').gsub(/\n/,' ')
    System::exec_split_lines(command,'|')
  end

  ##
  # Fair-Share distribution by users 
  #
  def sshare

    # Get the current version of the sshare program
    #
    version = `sshare --version`.split(' ')[-1]

    # Unfortunately it is required to execute sshare with version
    # dependent flags until support fr Slurm prior to version 15
    # is dropped...
    #
    command = case version

              # Old versions of Slurm
              # 
              when /^14/
                'sshare -alhP'

              # Beginning with version 15 the sshare command supports a --format option
              # 
              else
                "sshare --format #{sshare_fields} --all --parsable2 --noheader"

              end

    System::exec_split_lines(command,'|')

  end



  module Analyse

    module_function

    # Statistical analysis of the Slurm accounting data
    #
    #
    def data(i_data)


      # This object holds the output data
      #
      o_data = {
        'accounts' => Hash.new,
        'users' => Hash.new,
        'partitions' => Hash.new,
        'raw_time' => 0,
        'job_count' => 0
      }
      
      # Iterate over the input data, each line contains information about a single job
      #
      i_data.each do |elem|

        # This objects stores all data about a job
        #
        job = {}

        # Make the input data accessible by field name
        #
        Slurm::SACCT_FIELDS.each { |field| job[field] = elem[Slurm::sacct_findex field] }

        a_name = job['account']
        u_name = job['user']
        nodelist = job['nodelist']

        ##
        #
        # Evaluate command line options...
        #
        # Skip if the request nodes have not been part of this job allocation
        unless $options.node_regex.empty?
          next unless nodelist =~ Regexp.new($options.node_regex)
        end

        r_time = job['cputimeraw'].to_i
        p_name = job['partition']
        # This may include states  like "CANCELLED by 1234",
        # therefore everything after the first space is removed
        state  = job['state'].gsub(/\s.*/,'').downcase
        # Accumulate accounting data for the individual accounts
        #
        run_time = case
                   when r_time < 300    ; 'lt_5m'
                   when r_time < 3600   ; 'lt_1h'
                   when r_time < 14400  ; 'lt_4h'
                   when r_time < 28800  ; 'lt_8h'
                   when r_time < 43200  ; 'lt_12h'
                   when r_time < 86400  ; 'lt_1d'
                   when r_time < 604800 ; 'lt_7d'
                   else                 ; 'gt_7d'
                   end


        ##
        # Initialize the account data structure
        #
        if not o_data['accounts'].has_key? a_name
          o_data['accounts'][a_name] = {
            'users' => {},              # List of users 
            'partitions' => {},         # List of partitions 
            'raw_time' => 0,            # Total accumulated run-time on this account 
            'job_count' => 0,           # Total number of executed jobs
            'job_states' => {},         # Total number of jobs in certain exit states
            'wait_time' => [],          # Time in seconds jobs waited in the queue 
            'run_time' => {             # Jobs run-time...
              'lt_5m'  => 0,            # less then 5 minutes
              'lt_1h'  => 0,            # less then 1 hour
              'lt_4h'  => 0,            # less then 4 hours
              'lt_8h'  => 0,            # less then 8 hours
              'lt_12h' => 0,            # less then 12 hours
              'lt_1d'  => 0,            # less then 24 hours
              'lt_7d'  => 0,            # less then 7 days
              'gt_7d'  => 0             # greater then 7 days
            }
          }
          Slurm::SACCT_STATES.each do |state| 
            o_data['accounts'][a_name]['job_states'][state] = 0
          end
        end

        ##
        # Initialize the users data structure
        #
        if not o_data['users'].has_key? u_name
          o_data['users'][u_name] = {
            'accounts'     => {},       # List of accounts used
            'partitions'   => {},       # List of partitions used
            'raw_time'     => 0,        # Total accumulated run-time
            'job_count'    => 0,        # Total number of executed jobs
            'job_states'   => {},       # Total number of jobs in certain exit states
            'wait_time'    => [],       # Time in seconds jobs waited in the queue
            'run_time'     => {         # Jobs run-time...
              'lt_5m'  => 0,            # less then 5 minutes
              'lt_1h'  => 0,            # less then 1 hour
              'lt_4h'  => 0,            # less then 4 hours
              'lt_8h'  => 0,            # less then 8 hours
              'lt_12h' => 0,            # less then 12 hours
              'lt_1d'  => 0,            # less then 24 hours
              'lt_7d'  => 0,            # less then 7 days
              'gt_7d'  => 0             # greater then 7 days
            }
          }
          Slurm::SACCT_STATES.each do |state| 
            o_data['users'][u_name]['job_states'][state] = 0
          end
        end

        if not o_data['partitions'].has_key? p_name
          o_data['partitions'][p_name] = {
            'accounts' => {},           # List of accounts
            'users' => {},              # List of users 
            'raw_time' => 0,            # Total accumulated run-time
            'job_count' => 0,           # Total number of executed jobs
            'job_states' => {},         # Total number of jobs in certain exit states
            'wait_time' => [],          # Time in seconds jobs waited in the queue
            'run_time' => {             # Jobs run-time...
              'lt_5m'  => 0,            # less then 5 minutes
              'lt_1h'  => 0,            # less then 1 hour
              'lt_4h'  => 0,            # less then 4 hours
              'lt_8h'  => 0,            # less then 8 hours
              'lt_12h' => 0,            # less then 12 hours
              'lt_1d'  => 0,            # less then 24 hours
              'lt_7d'  => 0,            # less then 7 days
              'gt_7d'  => 0             # greater then 7 days
            }
          }
          Slurm::SACCT_STATES.each do |state| 
            o_data['partitions'][p_name]['job_states'][state] = 0
          end
        end

        ##
        # Populate the output object with statistical data 
        #
        # Accumulated CPU time consumed by all users/accounts
        o_data['raw_time'] += r_time
        # Total number of jobs executed by all users/accounts
        o_data['job_count'] += 1
        #
        # Account specific data...
        #
        unless o_data['accounts'][a_name]['partitions'].has_key? p_name
          o_data['accounts'][a_name]['partitions'][p_name] = Hash.new
        end
        unless o_data['accounts'][a_name]['users'].has_key? u_name
          o_data['accounts'][a_name]['users'][u_name] = Hash.new
        end
        o_data['accounts'][a_name]['raw_time'] += r_time
        o_data['accounts'][a_name]['job_count'] += 1
        o_data['accounts'][a_name]['job_states'][state] += 1
        o_data['accounts'][a_name]['run_time'][run_time] += 1
        #
        # User specific data
        #
        unless o_data['users'][u_name]['accounts'].include? a_name
          o_data['users'][u_name]['accounts'][a_name] = Hash.new
        end
        unless o_data['users'][u_name]['partitions'].include? a_name
          o_data['users'][u_name]['partitions'][p_name] = Hash.new
        end
        o_data['users'][u_name]['raw_time'] += r_time
        o_data['users'][u_name]['job_count'] += 1
        o_data['users'][u_name]['job_states'][state] += 1
        o_data['users'][u_name]['run_time'][run_time] += 1
        #
        # Partition specific data
        # 
        unless o_data['partitions'][p_name]['accounts'].has_key? a_name
          o_data['partitions'][p_name]['accounts'][a_name] = Hash.new
        end
        unless o_data['partitions'][p_name]['users'].has_key? u_name
          o_data['partitions'][p_name]['users'][u_name] = Hash.new
        end
        o_data['partitions'][p_name]['raw_time'] += r_time
        o_data['partitions'][p_name]['job_count'] += 1
        o_data['partitions'][p_name]['job_states'][state] += 1
        o_data['partitions'][p_name]['run_time'][run_time] += 1
       
        # Calculate time the job waited in the queue
        #
        submit_epoch = DateTime.strptime(job['submit'],'%Y-%m-%YT%H:%M').to_time.to_i 
        start_epoch = DateTime.strptime(job['start'],'%Y-%m-%YT%H:%M').to_time.to_i 
        wait_time_secs = start_epoch - submit_epoch
        if not wait_time_secs > 31449600 # 364 days
          o_data['accounts'][a_name]['wait_time'] << wait_time_secs
          o_data['users'][u_name]['wait_time'] << wait_time_secs
          o_data['partitions'][p_name]['wait_time'] << wait_time_secs
        end

      end

      ##
      ## Post processing of output data
      ##
      o_data['accounts'].each do |name,data|
        # Relative percent of the consumed resources according to the CPU seconds
        r_perc = sprintf '%.2f', (data['raw_time'].to_f/o_data['raw_time']) * 100
        o_data['accounts'][name]['rel_percent'] = r_perc
        # Median wait time of jobs in queue
        o_data['accounts'][name]['wait_time'] = data['wait_time'].median
      end
      o_data['users'].each do |name,data|
        # Relative percent of the consumed resources according to the CPU seconds
        r_perc = sprintf '%.2f', (data['raw_time'].to_f/o_data['raw_time']) * 100
        o_data['users'][name]['rel_percent'] = r_perc
        # Median wait time of jobs in queue
        o_data['users'][name]['wait_time'] = data['wait_time'].median
      end
      o_data['partitions'].each do |name,data|
        # Relative percent of the consumed resources according to the CPU seconds
        r_perc = sprintf '%.2f', (data['raw_time'].to_f/o_data['raw_time']) * 100
        o_data['partitions'][name]['rel_percent'] = r_perc
        # Median wait time of jobs in queue
        o_data['partitions'][name]['wait_time'] = data['wait_time'].median
      end

      return o_data

    end

    def shares

      shares = Hash.new
      
      ##
      # Populate the output object with the input data
      #
      Slurm::sshare.each do |elem|

        rec = {}

        Slurm::SSHARE_FIELDS.each { |field| rec[field] = elem[Slurm::sshare_findex field] }

        # Entities per input element
        account = rec['account']  
        user    = rec['user']
        r_share = rec['rawshare']
        n_share = rec['normshare']
        r_usage = rec['rawusage']
        n_usage = rec['normusage']
        e_usage = rec['effectvusage']
        f_share = rec['fairshare']

        # If this element describes an account...
        if user.empty?
          shares[account] = {
            'users' => {},
            'share' => { 'raw' => r_share, 'norm' => n_share },
            'usage' => { 'raw' => r_usage, 'norm' => n_usage },
            'effective_usage' => e_usage,
            'fair_share' => f_share
          }
        # If this element describes a user
        else
          shares[account]['users'][user] = {
            'share' => { 'raw' => r_share, 'norm' => n_share },
            'usage' => { 'raw' => r_usage, 'norm' => n_usage },
            'effective_usage' => e_usage,
            'fair_share' => f_share
          }
        end
      end

      return shares

    end

  end

end




def humanize_secs(seconds)
  days = seconds / (60*60*24)
  seconds = seconds % (60*60*24)
  hours = Time.at(seconds).utc.strftime('%H:%M')
  days > 0 ? "#{days}-#{hours}" : hours
end

class Array

  def median

    sym = '-'
    vals =  { 'average' => sym, 'median' => sym, 'lowest' => sym, 'highest' => sym }

    unless self.empty?

      # Average and median wait time of all jobs in queue 
      lowest = self.min 
      highest = self.max 
      total = self.inject(:+)
      length = self.length
      average = total.to_f/length
      sorted = self.sort
      median = if length > 0 
                 if length % 2 == 1 
                   sorted[length/2]
                 else
                   (sorted[length/2 - 1] + sorted[length/2]).to_f / 2
                 end
               else
                 0
               end

      vals =  { 
        'average' => average.to_i, 
        'median' => median.to_i,
        'lowest' => lowest,
        'highest' => highest
      }

    end

    return vals

  end

end

begin

  $options = OpenStruct.new
  $options.account = Array.new
  $options.debug = false
  $options.node_regex = String.new
  $options.no_header = false
  $options.parsable = Array.new
  $options.partition = Array.new
  $options.partitions = false
  $options.run_time = false
  $options.states = false
  $options.sortby = 'a'
  $options.users = false
  $options.user = Array.new
  

  $logger = Logger.new($stderr)
  # Adjust the time format used for the logger
  $logger.datetime_format = "%Y-%m-%dT%H:%M:%S "
  $logger.formatter = proc do |severity, datetime, progname, message|
    "[#{datetime.strftime($logger.datetime_format)}] #{severity} -- #{message}\n"
  end
  $logger.level = Logger::WARN

  GetoptLong.new(
    ['--account','-a',GetoptLong::REQUIRED_ARGUMENT],
    ['--debug','-d',GetoptLong::NO_ARGUMENT],
    ['--help','-H',GetoptLong::NO_ARGUMENT],
    ['--log-level','-L',GetoptLong::REQUIRED_ARGUMENT],
    ['--node-regex','-n',GetoptLong::REQUIRED_ARGUMENT],
    ['--no-header','-N',GetoptLong::NO_ARGUMENT],
    ['--parsable','-X',GetoptLong::REQUIRED_ARGUMENT],
    ['--partition','-p',GetoptLong::REQUIRED_ARGUMENT],
    ['--partitions','-P',GetoptLong::NO_ARGUMENT],
    ['--run-time','-R',GetoptLong::NO_ARGUMENT],
    ['--sort-by','-s',GetoptLong::REQUIRED_ARGUMENT],
    ['--states','-S',GetoptLong::NO_ARGUMENT],
    ['--user','-u',GetoptLong::REQUIRED_ARGUMENT],
    ['--users','-U',GetoptLong::NO_ARGUMENT],
    ['--version','-v',GetoptLong::NO_ARGUMENT]
  ).each do |opt,arg|
    case opt
    when '--account'
      $options.account = arg.split(',')
    when '--debug'
      $options.debug = true
      $logger.level = Logger::DEBUG
    when '--help'
      $stdout.puts HELP
      exit 0
    when '--log-level'
      $logger.level = case arg
      when 'warn'
        Logger::WARN
      when 'debug'
        Logger::DEBUG
      when 'fatal'
        Logger::FATAL
      else
        Logger::INFO
       end
    when '--node-regex'
      $options.node_regex = arg
    when '--no-header'
      $options.no_header = true
    when '--parsable'
      f_sep = Array.new
      # Make sure to use only the first character of a string
      f_sep << arg[0]
      # Make sure the first and second field separators are never the same
      if f_sep.first.eql? ','
        f_sep << '|'
      else
        f_sep << ','
      end
      $options.parsable = f_sep
    when '--partition'
      $options.partition = arg
    when '--partitions'
      $options.partitions = true
    when '--raw-json'
      $options.raw_json = true
    when '--run-time'
      $options.run_time = true
    when '--sort-by'
      $options.sortby = arg
    when '--states'
      $options.states = true
    when '--user'
      $options.user = arg.split(',')
    when '--users'
      $options.users = true
    when '--version'
      $stdout.puts VERSION
      exit 0
    end
  end

  time_format = '%Y-%m-%dT%H:%M:00'
  time_now = Time.now.strftime time_format

  # Users are required to define a start time
  #
  start_time = ARGV.shift || raise('Define a start time in the format YYYY-MM-DDTHH:MM:SS')

  # Users can optionally define an end time 
  #
  end_time = ARGV.shift || time_now

  #
  # Toggle options to sacct to select a subset of accounts, partitions and users.
  #
  append = ''
  if not $options.account.empty?
    append << " --accounts #{$options.account.join(',')}"
  end
  if not $options.user.empty?
    append << " --user #{$options.user.join(',')}"
  end
  if not $options.partition.empty?
    append << " --partition " << $options.partition
  end

  # Query Slurm for the required accounting data
  #
  i_data = Slurm::sacct(start_time,end_time,append)

  #
  # Accumulate statistics
  #
  o_data =  Slurm::Analyse::data(i_data) 

  ##
  #
  # ATTENTION
  #
  # This assumes that the fair share configuration has not been altered 
  # from the time frame of the accounting data until today. In other words
  # This retrieves to current configuration, not necessarily the configuration
  # at specified time frame:
  #
  shares = Slurm::Analyse::shares

  # Table containing the output data
  table = Array.new
  
  unless $options.no_header
    header = Array.new 
    header << 
      'ACCT' << 
      'USER' <<
      'PART' <<
      'USE%' <<
      'SHR%' <<
      'QWM' <<
      'RUNTIME' <<
      'JOBS'
    # If the user requires job state information
    header << 
      'CO' << 
      'CA' << 
      'F' << 
      'NF' << 
      'TO' if $options.states
    header <<
      '<5m' <<
      '<1h' <<
      '<4h' <<
      '<8h' <<
      '<12h' <<
      '<1d' <<
      '<7d' <<
      '>7d' if $options.run_time
    table << header
  end

  if $options.users
    sortby = o_data['users']
  elsif $options.partitions
    sortby = o_data['partitions']
  else
    sortby = o_data['accounts']
  end

  case $options.sortby
  # Sort by CPU seconds consumed/relative usage
  when 'r','p'
    rel = {}
    sortby.each { |n,d| rel[n] = d['raw_time'] }
    sortby = rel.sort_by { |k,v| v }.reverse.to_h.keys
  # Alphabetical order by default
  else 
    sortby = sortby.keys.sort
  end
  
  sortby.each do |elem|

    # Get the data for a given element
    data = if $options.users
             o_data['users'][elem]
           elsif $options.partitions
             o_data['partitions'][elem]
           else
             o_data['accounts'][elem]
           end

    partition = if $options.partitions
                  elem
                elsif not $options.parsable.empty?
                  # Print a list of all users with the second field separator
                  data['partitions'].keys.join($options.parsable.last)
                else
                  if data['partitions'].length > 1
                    data['partitions'].length
                  else
                    data['partitions'].keys.first
                  end
                end

    user = if $options.users
             elem
           elsif not $options.parsable.empty?
             # Print a list of all users with the second field separator
             data['users'].keys.join($options.parsable.last)
           else
             # Number of users which consumed resources
             data['users'].keys.length
           end

    account = if not $options.users or not $options.partitions
                elem
              elsif not $options.parsable.empty?
                # Print a list of all users with the second field separator
                data['accounts'].keys.join($options.parsable.last)
              else
                # The number of accounts a use has consumed resources from
                if data['accounts'].keys.length > 1
                  data['accounts'].keys.length
                else
                  data['accounts'].keys.first
                end
              end

    share = 0.0
    if $options.users
      # Accumulate fair share for a given user on all associated accounts
      data['accounts'].keys.each do |account|
        if shares.has_key? account
          share += shares[account]['users'][user]['share']['norm'].to_f * 100
        end
      end
      # Two digits fair share value
      share = sprintf('%.2f', share)
    elsif $options.partitions
      # Partitions don't have associated shares
      share = '-'
    else
      # Fair share configured for this account
      if shares.has_key? account
        share = sprintf('%.2f', shares[account]['share']['norm'].to_f*100)
      end
    end

    #
    # Assemble the fields for this table row
    #
    row = Array.new
    row << account
    row << user 
    row << partition
    row << data['rel_percent'] 
    row << share
    row << humanize_secs(data['wait_time']['median'].to_i)
    row << data['raw_time']
    row << data['job_count']  
    #
    # Job stats enable by user option
    #
    if $options.states
      row << data['job_states']['completed']
      row << data['job_states']['cancelled']
      row << data['job_states']['failed']
      row << data['job_states']['node_fail']
      row << data['job_states']['timeout']
    end
    #
    # Run time stats enable by user option
    #
    if $options.run_time
      row << data['run_time']['lt_5m']
      row << data['run_time']['lt_1h']
      row << data['run_time']['lt_4h']
      row << data['run_time']['lt_8h']
      row << data['run_time']['lt_12h']
      row << data['run_time']['lt_1d']
      row << data['run_time']['lt_7d']
      row << data['run_time']['gt_7d']
    end
    # Append row to output table
    table << row
  end

  if $options.parsable.empty?
    $stdout.puts Table::print table
  else
    table.each { |r| $stdout.puts "#{r.join($options.parsable.first)}" }
  end

rescue => exc
  $stderr.puts "ERROR: #{exc.message}"
  $stderr.puts " use -H for detailed instructions"
  if $options.debug
    $stderr.puts '-- Stack Trace --'
    $stderr.puts exc.backtrace
  else
    $stderr.puts 'You may want run this in debug mode with \'-d\''
  end
  exit 1
end

exit 0
